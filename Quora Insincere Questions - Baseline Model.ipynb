{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Introduction](#1)\n",
    "2. [Pre-Processing for Baseline](#2)\n",
    "3. [Baseline Model](#3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a></a>\n",
    "\n",
    "This notebook will document my new project to learn NLP, using the Quora Insincere Questions data source. I am attempting the challenge after the competition deadline has already passed, but in a Kaggle Kernel. After completing the project, I will download it and push to my Github repo.\n",
    "\n",
    "This notebook will begin with pre-processing and building a quick baseline model, using TF-IDF with logistic regression. Then I will peform some slightly different pre-processing for word embeddings (following advice from experienced kagglers) and then build an LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"../input/quora-insincere-questions-classification/train.csv\")\n",
    "test_set = pd.read_csv(\"../input/quora-insincere-questions-classification/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1306122, 3)\n",
      "Test shape :  (375806, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shape : \",train_set.shape)\n",
    "print(\"Test shape : \",test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1225312\n",
       "1      80810\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at some examples of positive and negative questions. The non-toxic questions are definitely the normal curious questions. The insincere questions look a bit random and seem written by weird people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    How did Quebec nationalists see their province...\n",
       "1    Do you have an adopted dog, how would you enco...\n",
       "2    Why does velocity affect time? Does velocity a...\n",
       "3    How did Otto von Guericke used the Magdeburg h...\n",
       "4    Can I convert montra helicon D to a mountain b...\n",
       "Name: question_text, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.query('target==0')['question_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22     Has the United States become the largest dicta...\n",
       "30     Which babies are more sweeter to their parents...\n",
       "110    If blacks support school choice and mandatory ...\n",
       "114    I am gay boy and I love my cousin (boy). He is...\n",
       "115                 Which races have the smallest penis?\n",
       "Name: question_text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.query('target==1')['question_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's tokenize using the NLTK package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_normal = train_set.query('target==0')['question_text'].apply(word_tokenize)\n",
    "tokens_insincere = train_set.query('target==1')['question_text'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda_preprocess(words):\n",
    "    # Remove single-character and 2 character tokens (mostly punctuation)\n",
    "    words = [word for word in words if len(word) > 2]\n",
    "\n",
    "    # Remove numbers\n",
    "    words = [word for word in words if not word.isnumeric()]\n",
    "\n",
    "    # Lowercase all words (default_stopwords are lowercase too)\n",
    "    words = [word.lower() for word in words]\n",
    "\n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in stopword_list]\n",
    "    \n",
    "    return words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_normal = tokens_normal.apply(eda_preprocess)\n",
    "tokens_insincere = tokens_insincere.apply(eda_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best 61636\n",
      "get 59445\n",
      "would 58072\n",
      "people 43397\n",
      "like 43133\n",
      "n't 38060\n",
      "good 36812\n",
      "one 32240\n",
      "india 29349\n",
      "make 26233\n",
      "time 22197\n",
      "think 22145\n",
      "someone 21846\n",
      "much 21463\n",
      "life 21361\n",
      "many 20919\n",
      "use 20746\n",
      "way 19732\n",
      "know 18481\n",
      "work 18111\n",
      "take 17339\n",
      "ever 16733\n",
      "find 16601\n",
      "want 16373\n",
      "could 15886\n",
      "become 15864\n",
      "without 15841\n",
      "person 15672\n",
      "better 14947\n",
      "world 14662\n"
     ]
    }
   ],
   "source": [
    "frequencies = Counter(word for sentence in tokens_normal for word in sentence)\n",
    "for word, frequency in frequencies.most_common(30):  # get the 10 most frequent words\n",
    "    print(word, frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the normal quora questions use the usual common words in the English language. And of course India is very common, since many quora users are Indian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people 12952\n",
      "n't 8324\n",
      "trump 6465\n",
      "like 5962\n",
      "women 5959\n",
      "would 4325\n",
      "men 4216\n",
      "think 3887\n",
      "white 3713\n",
      "many 3571\n",
      "muslims 3492\n",
      "quora 3407\n",
      "india 3291\n",
      "get 3226\n",
      "indian 3133\n",
      "black 2939\n",
      "americans 2916\n",
      "sex 2557\n",
      "indians 2508\n",
      "girls 2507\n",
      "world 2462\n",
      "want 2416\n",
      "hate 2236\n",
      "liberals 2097\n",
      "chinese 2089\n",
      "much 1974\n",
      "make 1963\n",
      "country 1933\n",
      "muslim 1903\n",
      "one 1816\n"
     ]
    }
   ],
   "source": [
    "frequencies = Counter(word for sentence in tokens_insincere for word in sentence)\n",
    "for word, frequency in frequencies.most_common(30):  \n",
    "    print(word, frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, insincere questions repeat controversial topics like Trump, gender, muslims, race and sex. By far everyone seems to be asking about controversial people or groups of people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How long are most sentences? We'll just count the tokenised versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_sentences(tokens):\n",
    "    length=[]\n",
    "    for sent in tokens:\n",
    "        length.append(len(sent))\n",
    "    \n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATwAAAEyCAYAAABnD2x2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEFxJREFUeJzt3V+MVOd5gPHnZcFs69YF4jWidlzSgNyNtorTjOJUsbCIa8tpq5iLpAqqIlStzE27SuJKjctKTXph5MiS3cqq6uJAwgWd/KGxQFGSFtGNopUiK0titaRbBLHiBJuaTcBKcMRmDW8vGFNMgZndObMzzPf8pNXMOXtm571Aj845M+cQmYkklWBJtweQpMVi8CQVw+BJKobBk1QMgyepGAZPUjEMnqRiGDxJxTB4koqxdDHf7Oabb861a9cu5ltKKsChQ4d+kplDzbZb1OCtXbuWqampxXxLSQWIiBdb2a7pIW1E3BERz1/y87OI+HhErIqIAxFxtPG4sv2xJalzmgYvM49k5p2ZeSfwbuAXwLPAI8DBzFwPHGwsS1LPmu+HFvcCP8jMF4EHgd2N9buBTVUOJklVm2/wPgLUG89XZ+YJgMbjLVd6QURsjYipiJiamZlZ+KSS1KaWgxcRNwAfBL48nzfIzB2ZWcvM2tBQ0w9RJKlj5rOH9wHgu5n5SmP5lYhYA9B4PFn1cJJUpfkEbzP/dzgLsB/Y0ni+BdhX1VCS1AktBS8ifhW4D/jKJasfA+6LiKON3z1W/XgqTb1eZ2RkhIGBAUZGRqjX681fJLWopS8eZ+YvgLdctu6nXPjUVqpEvV5nfHycnTt3cvfddzM5Ocno6CgAmzdv7vJ06gexmP+JT61WS6+00NWMjIzw1FNPsXHjxovrJiYmGBsb4/Dhw12cTL0uIg5lZq3pdgZPvWJgYICzZ8+ybNmyi+vm5uYYHBzk3LlzXZxMva7V4Hm3FPWM4eFhJicn37RucnKS4eHhLk2kfmPw1DPGx8cZHR1lYmKCubk5JiYmGB0dZXx8vNujqU8s6t1SpGt544OJsbExpqenGR4e5tFHH/UDC1XGc3iSrnuew5Okyxg8ScUweJKKYfAkFcPgSSqGwZNUDIMnqRgGT1IxDJ6kYhg8ScUweJKKYfAkFcPgSSqGwZNUDIMnqRgGT1IxDJ6kYhg8ScUweJKKYfAkFcPgSSpGS8GLiBURsTci/jsipiPi9yNiVUQciIijjceVnR5WktrR6h7e3wPfyMzfAd4JTAOPAAczcz1wsLEsST2rafAi4iZgA7ATIDN/mZmvAg8Cuxub7QY2dWpISapCK3t4vw3MAJ+LiO9FxGcj4kZgdWaeAGg83nKlF0fE1oiYioipmZmZygaXpPlqJXhLgd8D/jEz3wW8xjwOXzNzR2bWMrM2NDS0wDElqX2tBO84cDwzn2ss7+VCAF+JiDUAjceTnRlRkqrRNHiZ+T/AjyPijsaqe4H/AvYDWxrrtgD7OjKhJFVkaYvbjQF7IuIG4AXgz7gQyy9FxCjwI+DDnRlRkqrRUvAy83mgdoVf3VvtOJLUOV5pIakYBk9SMQyepGIYPEnFMHiSimHwJBXD4EkqhsGTVAyDJ6kYBk9SMQyepGIYPEnFMHiSimHwJBXD4EkqhsGTVAyDJ6kYBk9SMQyepGIYPEnFMHiSimHwJBXD4EkqhsGTVAyDp55Sr9cZGRlhYGCAkZER6vV6t0dSH1na7QGkN9TrdcbHx9m5cyd33303k5OTjI6OArB58+YuT6d+EJm5aG9Wq9Vyampq0d5P15eRkRGeeuopNm7ceHHdxMQEY2NjHD58uIuTqddFxKHMrDXdrpXgRcQPgZ8D54DXM7MWEauALwJrgR8Cf5KZp6/1dwyermVgYICzZ8+ybNmyi+vm5uYYHBzk3LlzXZxMva7V4M3nHN7GzLzzkj/6CHAwM9cDBxvL0oINDw8zOTn5pnWTk5MMDw93aSL1m3Y+tHgQ2N14vhvY1P44Ktn4+Dijo6NMTEwwNzfHxMQEo6OjjI+Pd3s09YlWP7RI4N8iIoF/yswdwOrMPAGQmSci4pZODakyvPHBxNjYGNPT0wwPD/Poo4/6gYUq0+o5vN/MzJcbUTsAjAH7M3PFJduczsyVV3jtVmArwO233/7uF198sbLhJQkqPoeXmS83Hk8CzwLvAV6JiDWNN1sDnLzKa3dkZi0za0NDQ63OL0mVaxq8iLgxIn79jefA/cBhYD+wpbHZFmBfp4aUpCq0cg5vNfBsRLyx/T9n5jci4jvAlyJiFPgR8OHOjSlJ7WsavMx8AXjnFdb/FLi3E0NJUid4La2kYhg8ScUweJKKYfAkFcPgSSqGwZNUDIMnqRgGT1IxDJ6kYhg8ScUweJKKYfAkFcPgSSqGwZNUDIMnqRgGT1IxDJ6kYhg8ScUweJKKYfAkFcPgSSqGwZNUDIMnqRgGT1IxDJ6kYhg8ScUweJKKYfAkFaPl4EXEQER8LyK+2lh+W0Q8FxFHI+KLEXFD58aUpPbNZw/vY8D0JcufAZ7MzPXAaWC0ysEkqWotBS8ibgP+CPhsYzmA9wN7G5vsBjZ1YkBJqkqre3h/B/wVcL6x/Bbg1cx8vbF8HLj1Si+MiK0RMRURUzMzM20NK0ntaBq8iPhj4GRmHrp09RU2zSu9PjN3ZGYtM2tDQ0MLHFOS2re0hW3eB3wwIv4QGARu4sIe34qIWNrYy7sNeLlzY0pS+5ru4WXmX2fmbZm5FvgI8O+Z+afABPChxmZbgH0dm1KSKtDO9/A+CTwcEce4cE5vZzUjSVJntHJIe1FmfhP4ZuP5C8B7qh9JkjrDKy0kFcPgSSqGwZNUDIMnqRgGT1IxDJ6kYhg8ScUweJKKYfAkFcPgSSqGwZNUDIMnqRgGT1IxDJ6kYhg8ScUweJKKYfAkFcPgqaeMjY0xODhIRDA4OMjY2Fi3R1IfMXjqGWNjYzz99NNs376d1157je3bt/P0008bPVUmMq/438l2RK1Wy6mpqUV7P11fBgcH2b59Ow8//PDFdU888QTbtm3j7NmzXZxMvS4iDmVmrdl27uGpZ8zOznLkyJE3HdIeOXKE2dnZbo+mPmHw1DMGBgZ45pln3nRI+8wzzzAwMNDt0dQnDJ56RmYSEW9aFxEs5mkX9TeDp55x/vx5HnroIbZt28aNN97Itm3beOihhzh//ny3R1OfMHjqGcuXL+fMmTOsW7eOJUuWsG7dOs6cOcPy5cu7PZr6hMFTz7jnnnvYs2cPGzZs4NSpU2zYsIE9e/Zwzz33dHs09QmDp57x0ksvsWnTJnbt2sWKFSvYtWsXmzZt4qWXXur2aOoTS5ttEBGDwLeA5Y3t92bmpyLibcAXgFXAd4GPZuYvOzms+tv09DTHjh27+DWU2dlZvv71rzM3N9flydQvWtnDmwXen5nvBO4EHoiI9wKfAZ7MzPXAaWC0c2OqBOfPn2d2dpbVq1czPT3N6tWrmZ2d9UMLVaZp8PKCM43FZY2fBN4P7G2s3w1s6siEKsqSJUuo1+u8/e1vp16vs2SJZ11UnZb+NUXEQEQ8D5wEDgA/AF7NzNcbmxwHbr3Ka7dGxFRETM3MzFQxs/rY448/fvEGAmNjYzz++OPdHkl9ZF7X0kbECuBZ4G+Az2Xmusb6twJfy8zfvdbrvZZW13L5l44v5ZePdS0duZY2M18Fvgm8F1gREW986HEb8PJ8h5Su5sknn+z2COpDTYMXEUONPTsi4leAPwCmgQngQ43NtgD7OjWkyvOJT3yi2yOoD7Wyh7cGmIiI/wC+AxzIzK8CnwQejohjwFuAnZ0bU6XYu3cvmXnxZ+/evc1fJLXI++GpZ3gOTwvl/fB0Xbvrrru6PYL6kMFTT3ruuee6PYL6kMGTVAyDp540NDTU7RHUhwyeetL999/f7RHUhwyeetKePXu6PYL6kMGTVAyDJ6kYBk9SMZre8VhabJdeVXGtqy+k+TJ46jlGTp3iIa2kYhg8ScUweJKKYfAkFcPgSSqGwZNUDIMnqRgGT1IxDJ6kYnilhXqOl5apUwyeeo6RU6d4SCupGAZPUjEMnqRiGDxJxTB4korRNHgR8daImIiI6Yj4fkR8rLF+VUQciIijjceVnR9XkhaulT2814G/zMxh4L3An0fEO4BHgIOZuR442FiWpJ7VNHiZeSIzv9t4/nNgGrgVeBDY3dhsN7CpU0NKUhXmdQ4vItYC7wKeA1Zn5gm4EEXglqqHk6QqtRy8iPg14F+Aj2fmz+bxuq0RMRURUzMzMwuZUZIq0VLwImIZF2K3JzO/0lj9SkSsafx+DXDySq/NzB2ZWcvM2tDQUBUzS9KCtPIpbQA7genMfOKSX+0HtjSebwH2VT+eJFWnlZsHvA/4KPCfEfF8Y9024DHgSxExCvwI+HBnRpSkajQNXmZOAle7fcW91Y4jSZ3jlRaSimHwJBXDG4Cq53jHY3WKwVPPMXLqFA9pJRXD4EkqhsGTVAyDJ6kYBk9SMQyepGIYPEnFMHiSimHwJBXDKy3Uc7y0TJ1i8NRzjJw6xUNaScUweJKKYfAkFcPgSSqGwZNUDIMnqRgGT1IxDJ6kYhg8ScXwSgv1HC8tU6e4hyepGO7hqee4V6dOMXhaVAuNWbPXXXoYLF1N00PaiNgVEScj4vAl61ZFxIGIONp4XNnZMdUvMrOln/lsa+zUqlbO4X0eeOCydY8ABzNzPXCwsSxJPa1p8DLzW8Cpy1Y/COxuPN8NbKp4Lkmq3EI/pV2dmScAGo+3XG3DiNgaEVMRMTUzM7PAt5Ok9nX8aymZuSMza5lZGxoa6vTbSdJVLTR4r0TEGoDG48nqRpKkzlho8PYDWxrPtwD7qhlHkjqnla+l1IFvA3dExPGIGAUeA+6LiKPAfY1lSeppTb94nJmbr/KreyueRZI6ymtpJRXD4EkqhsGTVAyDJ6kYBk9SMbw9lNq2atUqTp8+Xfnfrfq+eCtXruTUqcsvC1dJDJ7advr06eviFk3eWFQe0koqhsGTVAyDJ6kYBk9SMQyepGL4Ka3alp+6CT79G90eo6n81E3dHkFdZvDUtvjbn103X0vJT3d7CnWTh7SSimHwJBXDQ1pV4nq4imHlSv+/+NIZPLWtE+fvIuK6OC+o64uHtJKKYfAkFcPgSSqGwZNUDIMnqRgGT1IxDJ6kYhg8ScUweJKK0VbwIuKBiDgSEcci4pGqhpKkTlhw8CJiAPgH4APAO4DNEfGOqgaTpKq1s4f3HuBYZr6Qmb8EvgA8WM1YklS9dm4ecCvw40uWjwN3Xb5RRGwFtgLcfvvtbbyd+sF87qoyn2290YBa0c4e3pX+Nf6/f3WZuSMza5lZGxoaauPt1A8ysyM/UivaCd5x4K2XLN8GvNzeOJLUOe0E7zvA+oh4W0TcAHwE2F/NWJJUvQWfw8vM1yPiL4B/BQaAXZn5/comk6SKtXXH48z8GvC1imaRpI7ySgtJxTB4koph8CQVw+BJKobBk1QMgyepGAZPUjFiMa9DjIgZ4MVFe0Ndz24GftLtIXTd+K3MbHqx/qIGT2pVRExlZq3bc6i/eEgrqRgGT1IxDJ561Y5uD6D+4zk8ScVwD09SMQyepGIYPPWUiNgVEScj4nC3Z1H/MXjqNZ8HHuj2EOpPBk89JTO/BZzq9hzqTwZPUjEMnqRiGDxJxTB4koph8NRTIqIOfBu4IyKOR8Rot2dS//DSMknFcA9PUjEMnqRiGDxJxTB4koph8CQVw+BJKobBk1SM/wVniK2QwV9L8QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(figsize=(5,5))\n",
    "plt.boxplot(count_sentences(tokens_normal))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(figsize=(5,5))\n",
    "plt.boxplot(count_sentences(tokens_insincere))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The insincere questions on average are longer. Perhaps people spamming and repeating same words over and over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "from statistics import median \n",
    "print(median(count_sentences(tokens_insincere)))\n",
    "print(median(count_sentences(tokens_normal)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing for Baseline <a></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes punctuation\n",
    "import re, string\n",
    "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "def tokenize(s): return re_tok.sub(r' \\1 ', s).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train_set['question_text']\n",
    "test_text = test_set['question_text']\n",
    "train_target = train_set['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectoriser = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n",
    "               min_df=3, max_df=0.9, strip_accents='unicode')\n",
    "train_tfidf = tfidf_vectoriser.fit_transform(train_text)\n",
    "test_tfidf = tfidf_vectoriser.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression().fit(train_tfidf,train_target)\n",
    "y_pred = classifier.predict(test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = pd.DataFrame({\"qid\": test_set[\"qid\"], \"prediction\": y_pred})\n",
    "submit_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leaderboard score ~0.56 for both SVM and LogisticReg (default params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
